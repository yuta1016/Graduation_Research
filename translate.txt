・リズム
2.4. 周期性ヒストグラム (PH)
周期性ヒストグラムは、もともとビートトラッキングの文脈で提示されました [14]。同様のアプローチがジャンル分類にも開発されました [5]。我々が用いる類似度指標とこれら2つのアプローチの違いに関する詳細は、[7] に記載されています。
その考え方は、周波数に関わらず、周期的に繰り返されるビート（のみ）を記述することです。特徴は、Sone/Bark表現をさらに処理することで抽出されます。まず、打楽器音を強調するために、各Barkバンドに半波整流差分フィルタを適用します。次に、信号を12秒のセグメントに分割し、個別にさらに処理します。各シーケンスは、Hannウィンドウを用いて重み付けされた後、40bpmから240bpmの範囲で5bpmの分解能を持つコムフィルタバンクを各Barkバンドに適用します。次に、コムフィルタから得られた振幅に共鳴モデルを適用します。特定の周期におけるピークを強調するために、全帯域にわたって各周期の振幅を合計する前に、全波整流差分フィルタが使用されます。
12秒間の表現は、異なる周波数（bpm）を表す40の等間隔の列と、強度レベルを表す50の行を持つ2次元ヒストグラムを使用して要約されます。ヒストグラムは、各周期について、特定の値以上のレベルに達した回数をカウントします。2つのPH間の距離は、2つのSH間の距離と同じ方法で計算されます。
図2dは、最初のピークが60bpm付近、
80bpm付近の小さなピーク、120bpm付近の高いピーク、そして160bpm付近の非常に小さなピークが続くPHを示しています。

sss

FP [4] とPHの主な違いの一つは、
FPはBarkバンドの周期性を検出するために、計算コストの高いくし形フィルタではなく、単純なFFTを使用していることです。さらに、
PHは約120bpmで最大値を示す共鳴モデルを使用するのに対し、FPは4Hz（240bpm）でピークを示す変動モデルを使用しています。しかし、最大の違いは、
FPはスペクトルに関する情報を含むのに対し、PHはこの情報を無視していることです。
図2eは、2Hz（120bpm）付近の最も低い3つのBark帯域にピークがあり、4Hzでは全帯域にわたってより弱いピークがあるFPを示しています。PHとは異なり、2Hz未満のピークは見られません。

sss

楽曲の特定の瞬間におけるリズムの特徴を定量化するために、変動パターン（FP）[31]を用います。音声信号には、1秒ごとに移動する2.97秒長のハミング窓が適用されます。窓処理された音声セグメントはさらに256フレーム（44.1kHzサンプリングで512サンプルを含む）に分割されます。各フレームに対して高速フーリエ変換（FFT）を適用し、各周波数帯域の周期性ヒストグラム[31]を測定することで、フレームのFPを取得します。 256個のFPの平均値がセグメントのリズム成分として定義されます。


-------------------------------------------
・timber
楽曲の音色成分は、主に周波数成分によって決定されます。そのため、音声信号のスペクトル的側面の知覚的表現に広く用いられるメル周波数ケプストラム係数（MFCC）[32]を用います。リズムの場合と同様に、与えられた音声信号に2.97秒のハミング窓を適用し、窓処理されたセグメントを256フレームに分割します。各フレームには、36個のメル周波数間隔のビンを使用します。最後に、256フレームのMFCCを平均化します。


--------------------------------------------
・arousal
覚醒度：心理音響理論に基づく別の種類の複雑性特性、Arousal（覚醒度）を使用します。音楽の音量は感情の覚醒度と相関していることが知られています[33]。また、感情は音楽の嗜好を決定する重要な要因です[34]。したがって、音楽の嗜好（ひいては音楽の人気）は覚醒度によって影響を受けると推測できます。
2.97秒のハミング窓を用いて1秒ずつ移動させ、得られたセグメントの短時間振幅（すなわち、信号絶対値の合計）を計算します。次に、短時間振幅の平均値（ArousalMean）と標準偏差（ArousalStd）を時間経過にわたって計算し、音量の平均値と変動をそれぞれ測定します。


----------------------------------------
・sc
各成分についてSCを計算し、時間経過に伴う複雑性特徴を得る。観測ウィンドウの長さがwj = 2j−1であるi番目のセグメントのSCは、次式で与えられる。
SCij = JSD(si−wj:i−1,si:i+wj−1)
(2)
ここで、JSD(x,y)はxとyの間のJenson-Shannonダイバージェンス、sa:bはa番目からb番目のセグメントのsの値の合計である。観測ウィンドウは複雑性を測定する時間範囲を決定する。クロマについてはj =3,4,...,8、リズムと音色についてはj =1,2,...,6とし、これらは1秒から32秒のウィンドウ長に対応する。最後に、時間経過に伴うSCの平均値をとり、各特徴と各ウィンドウサイズについて単一の値を得る。その結果、クロマ、リズム、音色の各要素について、6つの観測ウィンドウ長に対する6つの複雑度特徴量（クロマ1～クロマ6、リズム1～リズム6、音色1～音色6）が得られます。


------------------------------------------------
・MFCC
compから
[21]では、ヒット曲予測のための楽曲のスペクトル特性を測定するためにMFCCに基づく特徴量が使用された。本研究でも[21]の特徴抽出手順を実装することでこれを採用する。
各オーディオ信号は、隣接するセグメント間のオーバーラップが0.015秒である長さ0.025秒のセグメントに分割され、各セグメントから20個のMFCCが抽出される。学習データセット内の楽曲の抽出されたMFCCに対して、ノイズを低減しコンパクトな特徴量を得るために、k-meansクラスタリングが実行され、32個のクラスター重心が得られる。これらの重心は、学習データで見つかった最も一般的な音響特性を表す。テスト用の楽曲が与えられると、そのMFCCベクトルの最小距離重心が検出され、32個のクラスターの正規化された周波数が楽曲の特徴量として得られる。

mfccの方から
まず、1700曲の実験データベースの各楽曲を音響的表現と歌詞ベースの表現に変換します。
前述の通り、各楽曲を音響的表現に変換する最初のステップは、
一般的な音声データセット(traning copra)内で最も顕著なN個のクラスターを学習することです。具体的には、
まずトレーニングセットの各楽曲を、10ms間隔でサンプリングした25msのオーバーラップするウィンドウから計算された
20次元のMFCCベクトルの系列に変換します。各ベクトルの0番目（DC）成分を除去した後、
K-meansクラスタリングを実行してN個の最も顕著な音声を学習する。計算上の理由から、
音響データを持つ全18,500曲を用いてこれらのクラスターを学習しない。
代わりに、K-meansモデルを学習するために約200曲でこのデータベースからサンプリングする。
次に実験用データベースの各楽曲を以下の手順でN次元ベクトルに変換する。
従来と同様に各楽曲を一連のMFCCベクトルに変換する。各ベクトルについてN個のクラスターそれぞれに対するスコアを算出し、
最高スコアのクラスターのカウンタをインクリメントする。正規化されたカウント値の集合がその楽曲のN次元表現となる。




----------------------------------------------------
セットアップ：分類器としてサポートベクターマシン（SVM）を使用する。6 
抽出した特徴量を用いてSVMを学習させ、各人気度指標の2値分類を実行する。2つのクラスの境界は、学習データセットにおける各人気度指標の中央値に設定される。SVMのカーネル関数としてラジアル基底関数（RBF）を使用する。ペナルティ係数とRBF関数の幅の値は、検証データセットに対して経験的に決定する。libsvmパッケージ7 [35] を使用する。
特徴量の人気度予測性能を調査するために、3つの異なる実験を計画する。
1) 各複雑度特徴量を用いた予測
2) 各特徴量グループを用いた予測
3) 複合特徴量を用いた予測
最初の実験では、分類器を単一の特徴量で学習させ、各複雑度特徴量が人気度指標を予測できるかどうか、そしてどの特徴量が予測に効果的かを調べる。
2番目の実験では、各特徴グループ（複雑度、MPEG、MFCC）の予測性能を比較します。最後に、3番目の実験では、複雑度に加えてMFCCまたはMPEG、あるいはその両方を併用した場合の性能向上を検証します。

2つのクラスのデータ数の違いを補正するために、分類性能はバランス精度で測定されます。バランス精度は次のように定義されます。
BA = 1/2{tp/(tp + fn) + tn/(tn + fp)}  (3)
ここで、tp、tn、fp、fnはそれぞれ真陽性（ヒット）、真陰性（正しい拒否）、偽陽性（誤報）、偽陰性（ミス）の数です。